# Timing Performance Visualizations

This directory contains comprehensive visualizations comparing the performance of CoreML, MLX, and PyTorch implementations of SimulStreamingMLX.

## Generated Visualizations

### 1. **Encoding Performance Comparison** (`encoding_comparison.html/png`)
- **Distribution Analysis**: Histograms showing encoding time distributions for each implementation
- **Box Plot Comparison**: Statistical comparison with outlier detection
- **Time Series**: Encoding performance over time
- **Performance Summary**: Mean encoding times with statistical measures

### 2. **Decoding Performance Comparison** (`decoding_comparison.html/png`)
- **Step Analysis**: Decoding time vs step number relationship
- **Distribution Analysis**: Histograms of decoding time distributions
- **Token Scaling**: Relationship between total tokens and decoding time
- **Performance Summary**: Mean decoding times across implementations

### 3. **Inference Performance Comparison** (`inference_comparison.html/png`)
- **Total Time Distribution**: Histograms of complete inference times
- **Complexity Analysis**: Inference time vs number of decode steps
- **Time Series**: Inference performance over time
- **Performance Summary**: Statistical comparison of total inference times

### 4. **Comprehensive Performance Summary** (`comprehensive_summary.html/png`)
- **Side-by-side Comparison**: Encoding, decoding, and inference performance
- **Error Bars**: Standard deviation visualization
- **Statistical Measures**: Mean and variance comparison
- **Overall Performance Ranking**: Visual comparison of all metrics

### 5. **Scaling Analysis** (`scaling_analysis.html/png`)
- **Decoding Scaling**: How decoding time scales with sequence length
- **Inference Scaling**: How total inference time scales with complexity
- **Error Analysis**: Confidence intervals for scaling relationships
- **Performance Trends**: Identification of scaling patterns

## Key Insights

### Data Processing
- **Outlier Filtering**: Removed top and bottom 5% of data points for stable analysis
- **Statistical Robustness**: All visualizations use filtered data to avoid extreme outliers
- **Sample Sizes**: Sufficient data points for reliable statistical analysis

### Performance Characteristics
- **CoreML**: Optimized for Apple Neural Engine acceleration
- **MLX**: Apple's ML framework optimized for Apple Silicon
- **PyTorch**: Traditional deep learning framework baseline

### Visualization Features
- **Interactive HTML**: Hover for detailed data points
- **Static PNG**: High-quality images for reports and presentations
- **Consistent Color Scheme**: Red (CoreML), Teal (MLX), Blue (PyTorch)
- **Statistical Measures**: Mean, median, standard deviation, min/max

## Usage

### Viewing Visualizations
1. **Interactive**: Open any `.html` file in a web browser
2. **Static**: View `.png` files in any image viewer
3. **Analysis**: Use hover tooltips and zoom features in HTML files

### Data Interpretation
- **Lower is Better**: All timing metrics are in milliseconds
- **Consistency**: Lower standard deviation indicates more stable performance
- **Scaling**: Linear scaling indicates good algorithmic efficiency
- **Outliers**: Filtered data provides more representative performance metrics

## Technical Details

### Data Sources
- `timing_logs_coreml/`: CoreML implementation timing data
- `timing_logs_mlx/`: MLX implementation timing data  
- `timing_logs_pytorch/`: PyTorch implementation timing data

### Generated By
- **Script**: `visualize_timing_comparison.py`
- **Framework**: Plotly for interactive visualizations
- **Format**: HTML (interactive) and PNG (static)
- **Filtering**: 5% outlier removal for statistical stability

### Performance Metrics
- **Encoding Time**: Time to process audio features
- **Decoding Time**: Time per decoding step
- **Inference Time**: Total time for complete inference
- **Scaling**: Performance relationship with input complexity

## Recommendations

### For Performance Analysis
1. Focus on **Comprehensive Summary** for overall comparison
2. Use **Scaling Analysis** to understand algorithmic efficiency
3. Check **Distribution Analysis** for performance consistency
4. Consider **Time Series** for performance stability over time

### For Reporting
1. Use **PNG files** for presentations and documents
2. Use **HTML files** for interactive exploration
3. Reference **statistical measures** for quantitative comparisons
4. Consider **outlier filtering** when interpreting results

---

*Generated by SimulStreamingMLX Timing Analysis Tool*
